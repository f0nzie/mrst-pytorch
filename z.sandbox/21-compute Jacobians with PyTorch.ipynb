{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"21-compute Jacobians with PyTorch.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"RcFWivw3zreb","colab_type":"code","outputId":"60f39625-d7f0-4179-a23e-4d2fe20cec03","executionInfo":{"status":"ok","timestamp":1576267111699,"user_tz":360,"elapsed":6122,"user":{"displayName":"ALFONSO REYES","photoUrl":"","userId":"07474635334369434839"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["# https://gist.github.com/sbarratt/37356c46ad1350d4c30aefbd488a4faa\n","# https://gist.github.com/sbarratt/37356c46ad1350d4c30aefbd488a4faa#gistcomment-2987842\n","\n","import torch\n","torch.manual_seed(123)\n","\n","def compute_jacobian(f, x, output_dims):\n","    '''\n","    Normal:\n","        f: input_dims -> output_dims\n","    Jacobian mode:\n","        f: output_dims x input_dims -> output_dims x output_dims\n","    '''\n","    repeat_dims = tuple(output_dims) + (1,) * len(x.shape)\n","    jac_x = x.detach().repeat(*repeat_dims)\n","    jac_x.requires_grad_()\n","    # print(jac_x.shape)\n","    jac_y = f(jac_x)\n","    \n","    ml = torch.meshgrid([torch.arange(dim) for dim in output_dims])\n","    index = [m.flatten() for m in ml]\n","    gradient = torch.zeros(output_dims + output_dims)\n","    gradient.__setitem__(tuple(index)*2, 1)\n","    \n","    jac_y.backward(gradient)\n","        \n","    return jac_x.grad.data\n","\n","def g(x):\n","  return x*x @ w\n","\n","def h(x):\n","  return 3*x @ w\n","\n","\n","w = torch.randn(4, 3)\n","f = lambda x: x @ w\n","x = torch.randn(2,3,4)\n","\n","jac_f = compute_jacobian(f, x, [2,3,3])\n","jac_g = compute_jacobian(g, x, [2,3,3])\n","jac_h = compute_jacobian(h, x, [2,3,3])\n","\n","print(jac_f.sum())\n","print(jac_g.sum())\n","print(jac_h.sum())\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor(-19.6881)\n","tensor(-7.6844)\n","tensor(-59.0642)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_kVNSGWrgENa","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s20d9xUA3Nz7","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"he-j0GMJS4W1","colab_type":"text"},"source":["## Minibatch version of original get_jacobian code"]},{"cell_type":"code","metadata":{"id":"H5HSE-ziSSSe","colab_type":"code","outputId":"4dcbb798-161a-4c21-89f9-c3894149ad03","executionInfo":{"status":"ok","timestamp":1576274651530,"user_tz":360,"elapsed":5341,"user":{"displayName":"ALFONSO REYES","photoUrl":"","userId":"07474635334369434839"}},"colab":{"base_uri":"https://localhost:8080/","height":485}},"source":["# https://gist.github.com/sbarratt/37356c46ad1350d4c30aefbd488a4faa#gistcomment-3060003\n","\n","import torch\n","\n","def get_jacobian(net, x, num_outputs, batch_size=None, verbose=0):\n","    \"\"\"\n","    Compute jacobian matrix of network outputs w.r.t input x.\n","    \n","    Parameters\n","    ----------\n","    net: A pytorch callable (e.g a network instance)\n","\n","    num_outputs: int\n","        Number of outputs produced by net (per input instance)\n","        \n","    batch_size: int, optional\n","        If None, then do run in full-back mode. Else run in minibatch mode\n","        with mini-batches of size `batch_size`\n","    \"\"\"\n","\n","    from sklearn.utils import gen_batches\n","    import torch\n","\n","    if batch_size is None:\n","        batch_size = num_outputs\n","    num_batches = num_outputs / float(batch_size) + (num_outputs % batch_size != 0)\n","    x.requires_grad_(False)\n","    x = x.squeeze(0)\n","    shape = list(x.shape)\n","    ones = [1] * len(shape)\n","    jacs = torch.zeros([num_outputs] + shape)\n","    \n","    for b, batch in enumerate(gen_batches(num_outputs, batch_size)):\n","        this_batch_size = len(jacs[batch])\n","        x_ = x.repeat(this_batch_size, *ones).requires_grad_(True)\n","        output = net(x_)\n","        assert (len(output.shape) == 2 and len(output) == this_batch_size)\n","        output.backward(torch.eye(num_outputs)[batch, :])\n","        jacs[batch] = x_.grad\n","        if verbose and num_batches > 1:\n","            print(\"Batch %02i / %02i\" % (b + 1, num_batches))\n","   \n","    return jacs.data\n","\n","# Worked example\n","num_features = 2\n","num_outputs = 10\n","x = torch.ones(num_features)\n","W = torch.randn(num_features, num_outputs)\n","y = lambda z: z @ W + 2019\n","batch_size = 3\n","jacs = get_jacobian(y, x, num_outputs, batch_size, verbose=1)\n","print(\"dy/dx:\\n%s\" % jacs)\n","print(\"W.T:\\n%s\" % W.T)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Batch 01 / 04\n","Batch 02 / 04\n","Batch 03 / 04\n","Batch 04 / 04\n","dy/dx:\n","tensor([[ 0.2212,  0.4296],\n","        [ 0.6006,  1.0388],\n","        [-1.1592, -0.9876],\n","        [-0.2304,  0.4367],\n","        [ 1.3516,  1.6069],\n","        [-0.4817, -0.0126],\n","        [-0.7625,  0.0338],\n","        [ 0.7208, -1.3271],\n","        [-1.0591,  0.2027],\n","        [ 0.5967, -0.2911]])\n","W.T:\n","tensor([[ 0.2212,  0.4296],\n","        [ 0.6006,  1.0388],\n","        [-1.1592, -0.9876],\n","        [-0.2304,  0.4367],\n","        [ 1.3516,  1.6069],\n","        [-0.4817, -0.0126],\n","        [-0.7625,  0.0338],\n","        [ 0.7208, -1.3271],\n","        [-1.0591,  0.2027],\n","        [ 0.5967, -0.2911]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qVj41Ww8Sp7A","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CQjqfLuKW53m","colab_type":"text"},"source":["## The n-th derivative of a function"]},{"cell_type":"code","metadata":{"id":"y90NaLZoSqI6","colab_type":"code","outputId":"73eb2bf6-363b-4cf1-8c1f-88ea88b3b069","executionInfo":{"status":"ok","timestamp":1576276162961,"user_tz":360,"elapsed":385,"user":{"displayName":"ALFONSO REYES","photoUrl":"","userId":"07474635334369434839"}},"colab":{"base_uri":"https://localhost:8080/","height":215}},"source":["# https://stackoverflow.com/a/50375367/5270873\n","\n","import torch\n","from torch.autograd import grad\n","\n","def nth_derivative(f, wrt, n):\n","\n","    for i in range(n):\n","\n","        grads = grad(f, wrt, create_graph=True)[0]\n","        f = grads.sum()\n","\n","    return grads\n","\n","x = torch.arange(4.0, requires_grad=True).reshape(2, 2)\n","print(x)\n","loss = (x ** 3).sum() # a scalar\n","print(loss)\n","\n","print(nth_derivative(f=loss, wrt=x, n=1))\n","print(nth_derivative(f=loss, wrt=x, n=2))\n","print(nth_derivative(f=loss, wrt=x, n=3))\n","print(nth_derivative(f=loss, wrt=x, n=4))\n","# error if: print(nth_derivative(f=loss, wrt=x, n=5))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[0., 1.],\n","        [2., 3.]], grad_fn=<AsStridedBackward>)\n","tensor(36., grad_fn=<SumBackward0>)\n","tensor([[ 0.,  3.],\n","        [12., 27.]], grad_fn=<MulBackward0>)\n","tensor([[ 0.,  6.],\n","        [12., 18.]], grad_fn=<MulBackward0>)\n","tensor([[6., 6.],\n","        [6., 6.]], grad_fn=<MulBackward0>)\n","tensor([[0., 0.],\n","        [0., 0.]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"G1l1RtsDY35N","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OICslK-oAFYo","colab_type":"text"},"source":["## computes the Jacobian of any tensor w.r.t. any dimensional inputs"]},{"cell_type":"code","metadata":{"id":"WIgBKW6hSqWp","colab_type":"code","colab":{}},"source":["# https://stackoverflow.com/q/50322833/5270873\n","\n","import torch\n","import torch.autograd as ag\n","\n","def nd_range(stop, dims = None):\n","    if dims == None:\n","        dims = len(stop)\n","    if not dims:\n","        yield ()\n","        return\n","    for outer in nd_range(stop, dims - 1):\n","        for inner in range(stop[dims - 1]):\n","            yield outer + (inner,)\n","\n","\n","def full_jacobian(f, wrt):    \n","    f_shape = list(f.size())\n","    wrt_shape = list(wrt.size())\n","    fs = []\n","\n","\n","    f_range = nd_range(f_shape)\n","    wrt_range = nd_range(wrt_shape)\n","\n","    for f_ind in f_range:\n","        grad = ag.grad(f[tuple(f_ind)], wrt, retain_graph=True, create_graph=True)[0]\n","        for i in range(len(f_shape)):\n","            grad = grad.unsqueeze(0)\n","        fs.append(grad)\n","\n","    fj = torch.cat(fs, dim=0)\n","    fj = fj.view(f_shape + wrt_shape)\n","    return fj"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_J3nMFd0ZPf_","colab_type":"code","outputId":"968900d3-aeee-4a3f-f1fb-13c5dbbfddc6","executionInfo":{"status":"ok","timestamp":1576276465775,"user_tz":360,"elapsed":356,"user":{"displayName":"ALFONSO REYES","photoUrl":"","userId":"07474635334369434839"}},"colab":{"base_uri":"https://localhost:8080/","height":107}},"source":["x = torch.arange(4.0, requires_grad=True).reshape(2, 2)\n","\n","loss = (x ** 3).sum() # a scalar  \n","print(x)\n","print(loss)\n","\n","full_jacobian(loss, x)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[0., 1.],\n","        [2., 3.]], grad_fn=<AsStridedBackward>)\n","tensor(36., grad_fn=<SumBackward0>)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.,  3.],\n","        [12., 27.]], grad_fn=<ViewBackward>)"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"markdown","metadata":{"id":"_V6WCKIfSqpJ","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"kh2KY3YpJ57x","colab_type":"code","colab":{}},"source":["import torch\n","\n","from torch.autograd import grad\n","\n","def jacobian(inputs, outputs):\n","    return torch.stack([grad([outputs[:, i].sum()], [inputs], retain_graph=True, create_graph=True)[0]\n","                        for i in range(outputs.size(1))], dim=-1)\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2sTd9VNQgHdz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":377},"outputId":"b28dde85-293b-4240-beeb-eb5a581b00ec","executionInfo":{"status":"error","timestamp":1576295076170,"user_tz":360,"elapsed":335,"user":{"displayName":"ALFONSO REYES","photoUrl":"","userId":"07474635334369434839"}}},"source":["w = torch.randn(4,3)\n","f = lambda x: x @ w\n","x = torch.randn(2,3,4)\n","\n","jacobian(f, x)"],"execution_count":19,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-3bf409f96a60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mjacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-17-5c845386e4fb>\u001b[0m in \u001b[0;36mjacobian\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mjacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     return torch.stack([grad([outputs[:, i].sum()], [inputs], retain_graph=True, create_graph=True)[0]\n\u001b[0;32m----> 7\u001b[0;31m                         for i in range(outputs.size(1))], dim=-1)\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-17-5c845386e4fb>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mjacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     return torch.stack([grad([outputs[:, i].sum()], [inputs], retain_graph=True, create_graph=True)[0]\n\u001b[0;32m----> 7\u001b[0;31m                         for i in range(outputs.size(1))], dim=-1)\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    155\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[1;32m    156\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         inputs, allow_unused)\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"]}]},{"cell_type":"code","metadata":{"id":"mbEOIP5tKB7B","colab_type":"code","outputId":"339f932d-db33-495d-ad48-05bc6f810cf6","executionInfo":{"status":"error","timestamp":1576295080722,"user_tz":360,"elapsed":341,"user":{"displayName":"ALFONSO REYES","photoUrl":"","userId":"07474635334369434839"}},"colab":{"base_uri":"https://localhost:8080/","height":407}},"source":["x = torch.arange(4.0, requires_grad=True).reshape(2, 2) \n","loss = (x ** 3) # a scalar  \n","print(x)\n","print(loss) \n","jacobian(loss, torch.tensor([1.0]))"],"execution_count":20,"outputs":[{"output_type":"stream","text":["tensor([[0., 1.],\n","        [2., 3.]], grad_fn=<AsStridedBackward>)\n","tensor([[ 0.,  1.],\n","        [ 8., 27.]], grad_fn=<PowBackward0>)\n"],"name":"stdout"},{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-6675f8e2e92d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mjacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-17-5c845386e4fb>\u001b[0m in \u001b[0;36mjacobian\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mjacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     return torch.stack([grad([outputs[:, i].sum()], [inputs], retain_graph=True, create_graph=True)[0]\n\u001b[0;32m----> 7\u001b[0;31m                         for i in range(outputs.size(1))], dim=-1)\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"]}]}]}